# Scaling and Speedrunning GPT-2

This repository is dedicated to work studying scaling in GPT-2 and speedrunning a la @kellerjordan0 and is work in progress.  The loss plot below was generating training a 124M parameter gpt-2 model on 8xA100s.

<img width="604" height="459" alt="image" src="https://github.com/aaronjhf/gpt-2/blob/main/gpt-2-small-loss.png" />
